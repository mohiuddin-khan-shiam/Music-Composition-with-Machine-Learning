{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsA2HZ6ZfVWw",
        "outputId": "f4aa50e5-02cc-4dd5-b807-e5dc04da20c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/5.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/5.6 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.26.4)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (24.2)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=c9b2b087f74cc22e9f0a2cdeecca0210e36f35bcff2ed20d340c23d65facb68d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "# Install required package (run this cell once)\n",
        "!pip install pretty_midi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import pretty_midi\n",
        "import os\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# ----- Step 1: Generate Synthetic Music Dataset -----\n",
        "\n",
        "# Define the MIDI note range (for example, notes from Middle C (60) to C above (72))\n",
        "vocab_start = 60\n",
        "vocab_end = 72\n",
        "vocab_size = vocab_end - vocab_start + 1  # e.g., 13 possible notes\n",
        "\n",
        "num_sequences = 1000          # Number of sequences to generate\n",
        "sequence_total_length = 50    # Total length of each generated sequence\n",
        "input_sequence_length = 20    # Length of input sequences for training\n",
        "\n",
        "# Generate synthetic sequences using a random walk so that adjacent notes are related.\n",
        "sequences = []\n",
        "for _ in range(num_sequences):\n",
        "    seq = []\n",
        "    # Start at a random note in the range\n",
        "    note = np.random.randint(vocab_start, vocab_end + 1)\n",
        "    seq.append(note)\n",
        "    for _ in range(1, sequence_total_length):\n",
        "        # Random step between -2 and +2 semitones\n",
        "        step = np.random.choice([-2, -1, 0, 1, 2])\n",
        "        note = note + step\n",
        "        # Ensure the note stays within our defined range\n",
        "        note = int(np.clip(note, vocab_start, vocab_end))\n",
        "        seq.append(note)\n",
        "    sequences.append(seq)\n",
        "\n",
        "# Create training examples by sliding over each sequence:\n",
        "X = []\n",
        "y = []\n",
        "for seq in sequences:\n",
        "    # Convert note values to indices (0 to vocab_size-1)\n",
        "    seq_indices = [note - vocab_start for note in seq]\n",
        "    for i in range(len(seq_indices) - input_sequence_length):\n",
        "        X.append(seq_indices[i:i+input_sequence_length])\n",
        "        y.append(seq_indices[i+input_sequence_length])\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Training examples:\", X.shape, y.shape)\n",
        "\n",
        "# ----- Step 2: Build and Train the LSTM Model -----\n",
        "\n",
        "embedding_dim = 64\n",
        "lstm_units = 128\n",
        "\n",
        "model = Sequential([\n",
        "    # The Embedding layer converts integer indices to dense vectors.\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_sequence_length),\n",
        "    LSTM(lstm_units),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "# Train the model (adjust epochs as needed; training on a synthetic dataset is fast)\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# ----- Step 3: Generate New Music -----\n",
        "\n",
        "def generate_music(seed_seq, gen_length=100, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generates a new sequence of note indices.\n",
        "    - seed_seq: a list of integers (length should equal input_sequence_length)\n",
        "    - gen_length: number of notes to generate\n",
        "    - temperature: controls randomness (higher => more random)\n",
        "    \"\"\"\n",
        "    generated = seed_seq.copy()\n",
        "    for _ in range(gen_length):\n",
        "        # Prepare the input sequence (reshape to (1, sequence_length))\n",
        "        input_seq = np.array(generated[-input_sequence_length:]).reshape(1, input_sequence_length)\n",
        "        predictions = model.predict(input_seq, verbose=0)[0]\n",
        "        # Apply temperature scaling\n",
        "        predictions = np.log(predictions + 1e-8) / temperature\n",
        "        exp_preds = np.exp(predictions)\n",
        "        predictions = exp_preds / np.sum(exp_preds)\n",
        "        # Sample the next note index from the probability distribution\n",
        "        next_index = np.random.choice(range(vocab_size), p=predictions)\n",
        "        generated.append(next_index)\n",
        "    return generated\n",
        "\n",
        "# Choose a random seed from the training set\n",
        "seed_index = np.random.randint(0, len(X))\n",
        "seed_sequence = list(X[seed_index])\n",
        "print(\"Seed sequence (indices):\", seed_sequence)\n",
        "\n",
        "generated_sequence = generate_music(seed_sequence, gen_length=100, temperature=1.0)\n",
        "\n",
        "# Convert indices back to MIDI note numbers\n",
        "generated_notes = [n + vocab_start for n in generated_sequence]\n",
        "print(\"Generated note sequence:\", generated_notes)\n",
        "\n",
        "# ----- Step 4: Convert Generated Notes to a MIDI File -----\n",
        "\n",
        "def notes_to_midi(notes, output_file=\"generated.mid\", note_duration=0.5, start_time=0.0):\n",
        "    \"\"\"\n",
        "    Converts a list of MIDI note numbers into a MIDI file.\n",
        "    - notes: list of MIDI note numbers (integers)\n",
        "    - output_file: name/path for the output MIDI file\n",
        "    - note_duration: duration (in seconds) for each note\n",
        "    - start_time: starting time offset\n",
        "    \"\"\"\n",
        "    pm = pretty_midi.PrettyMIDI()\n",
        "    instrument = pretty_midi.Instrument(program=0)  # Acoustic Grand Piano\n",
        "    current_time = start_time\n",
        "    for note in notes:\n",
        "        note_event = pretty_midi.Note(\n",
        "            velocity=100,\n",
        "            pitch=note,\n",
        "            start=current_time,\n",
        "            end=current_time + note_duration\n",
        "        )\n",
        "        instrument.notes.append(note_event)\n",
        "        current_time += note_duration\n",
        "    pm.instruments.append(instrument)\n",
        "    pm.write(output_file)\n",
        "    print(f\"MIDI file saved as '{output_file}'\")\n",
        "\n",
        "# Convert the generated note sequence into a MIDI file\n",
        "notes_to_midi(generated_notes, output_file=\"generated.mid\")\n",
        "\n",
        "# ----- (Optional) Listen to the MIDI File in Colab -----\n",
        "# Note: Colab's Audio player may not render MIDI directly.\n",
        "# For a better listening experience, you could convert the MIDI file to audio using a synthesizer.\n",
        "# Below, we simply provide a link to the MIDI file.\n",
        "if os.path.exists(\"generated.mid\"):\n",
        "    print(\"Generated MIDI file is available for download: 'generated.mid'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OycNuSqFfas_",
        "outputId": "ac93315d-045a-45ab-e391-ee720a73e98e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: (30000, 20) (30000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 45ms/step - loss: 1.9180\n",
            "Epoch 2/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - loss: 1.5096\n",
            "Epoch 3/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 1.4805\n",
            "Epoch 4/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 1.4677\n",
            "Epoch 5/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - loss: 1.4663\n",
            "Epoch 6/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 1.4621\n",
            "Epoch 7/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - loss: 1.4608\n",
            "Epoch 8/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 1.4533\n",
            "Epoch 9/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - loss: 1.4527\n",
            "Epoch 10/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - loss: 1.4502\n",
            "Epoch 11/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.4436\n",
            "Epoch 12/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.4433\n",
            "Epoch 13/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - loss: 1.4456\n",
            "Epoch 14/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - loss: 1.4443\n",
            "Epoch 15/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.4386\n",
            "Epoch 16/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - loss: 1.4356\n",
            "Epoch 17/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 1.4305\n",
            "Epoch 18/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 37ms/step - loss: 1.4291\n",
            "Epoch 19/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - loss: 1.4286\n",
            "Epoch 20/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 1.4220\n",
            "Epoch 21/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.4176\n",
            "Epoch 22/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - loss: 1.4062\n",
            "Epoch 23/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.4002\n",
            "Epoch 24/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - loss: 1.3965\n",
            "Epoch 25/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - loss: 1.3790\n",
            "Epoch 26/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 41ms/step - loss: 1.3707\n",
            "Epoch 27/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - loss: 1.3583\n",
            "Epoch 28/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 1.3496\n",
            "Epoch 29/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.3320\n",
            "Epoch 30/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 1.3215\n",
            "Epoch 31/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.2997\n",
            "Epoch 32/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - loss: 1.2867\n",
            "Epoch 33/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 1.2629\n",
            "Epoch 34/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - loss: 1.2500\n",
            "Epoch 35/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 1.2225\n",
            "Epoch 36/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - loss: 1.2046\n",
            "Epoch 37/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - loss: 1.1762\n",
            "Epoch 38/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 38ms/step - loss: 1.1515\n",
            "Epoch 39/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 1.1338\n",
            "Epoch 40/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - loss: 1.1016\n",
            "Epoch 41/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 39ms/step - loss: 1.0841\n",
            "Epoch 42/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 1.0583\n",
            "Epoch 43/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 1.0287\n",
            "Epoch 44/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 1.0052\n",
            "Epoch 45/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.9749\n",
            "Epoch 46/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - loss: 0.9415\n",
            "Epoch 47/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 0.9205\n",
            "Epoch 48/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - loss: 0.8901\n",
            "Epoch 49/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - loss: 0.8636\n",
            "Epoch 50/50\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.8390\n",
            "Seed sequence (indices): [9, 9, 9, 10, 10, 12, 12, 12, 12, 10, 8, 8, 6, 8, 6, 8, 9, 9, 11, 12]\n",
            "Generated note sequence: [69, 69, 69, 70, 70, 72, 72, 72, 72, 70, 68, 68, 66, 68, 66, 68, 69, 69, 71, 72, 70, 72, 72, 72, 70, 69, 71, 72, 71, 71, 69, 69, 71, 69, 71, 72, 70, 70, 69, 69, 70, 70, 70, 71, 70, 70, 72, 72, 72, 70, 70, 68, 68, 69, 70, 71, 72, 71, 72, 72, 72, 70, 71, 70, 71, 70, 72, 72, 71, 69, 71, 72, 71, 72, 70, 70, 71, 72, 72, 72, 72, 71, 71, 71, 72, 72, 72, 72, 70, 71, 70, 70, 71, 72, 70, 68, 67, 69, 70, 68, 68, 66, 64, 64, 65, 67, 67, 67, 69, 69, 69, 67, 69, 67, 66, 67, 67, 65, 67, 66]\n",
            "MIDI file saved as 'generated.mid'\n",
            "Generated MIDI file is available for download: 'generated.mid'\n"
          ]
        }
      ]
    }
  ]
}